{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b580359-84a6-474a-bcdf-1f098da8e87f",
   "metadata": {},
   "source": [
    "# __HoWDe__ \n",
    "### _a Home and Work location Detection algorithm for GPS data analytics_\n",
    "\n",
    "This notebook is intended to work as a brief tutorial on how to user \"HoWDe\". It leverages functions contained in the \"HoWDe_utils.py\" file (source code). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4dd5a79-6d0a-4463-844d-f995694edcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "# # NB: Home and Work location labelling\n",
    "# 1. Load pre-computed stop locations (in our case computed using infostop)\n",
    "# 2. Assigning labels to stop locations: Home (\"H\"), Work (\"W\"), and Other (\"O\")\n",
    "from howde import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90caa6b-93dd-4ce3-b10e-f9e1974bd559",
   "metadata": {},
   "outputs": [],
   "source": [
    "HW_PATH = None\n",
    "HW_PATH = './'\n",
    "\n",
    "\n",
    "try: assert type(HW_PATH) is str\n",
    "except: print(\"Path to data is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c43d5-5143-4a76-9515-f674297e6962",
   "metadata": {},
   "source": [
    "#### 1. Use HoWDe providing pre-loaded data and Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8db261-bb1f-4a27-b456-e9ff9daffa37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- useruuid: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- start: long (nullable = true)\n",
      " |-- end: long (nullable = true)\n",
      " |-- stop_duration: long (nullable = true)\n",
      " |-- location_type: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Load DATA and PASS it to HoWDe\n",
    "import os\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up Spark\n",
    "driver_memory=250\n",
    "packages = \"data/work/shared/tools/spark-avro_2.12-3.0.0.jar\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--jars {0} pyspark-shell \".format(packages)\n",
    "spark = (SparkSession\n",
    "            .builder.master(\"local[50]\")\n",
    "            .config(\"spark.sql.files.ignoreCorruptFiles\", \"true\")\n",
    "            .config(\"spark.driver.memory\", f\"{driver_memory}g\")\n",
    "            .config(\"spark.executor.memory\", \"250g\")\n",
    "            .getOrCreate()\n",
    ")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Load DATA\n",
    "input_data = spark.read.format(\"parquet\").load(HW_PATH, pathGlobFilter=\"*.parquet\")\n",
    "\n",
    "res1 = HoWDe_labelling(input_data = input_data, spark=spark, HW_PATH='./',\n",
    "                    SAVE_PATH=None, SAVE_NAME='', save_multiple=False,\n",
    "                    edit_config_default=None, \n",
    "                    range_window=42, dhn=6,\n",
    "                    dn_H=[0.4,0.6], dn_W=0.8,\n",
    "                    hf_H=0.2, hf_W=0.2,\n",
    "                    df_W=0.2,\n",
    "                    driver_memory = 250\n",
    "                   )\n",
    "\n",
    "res1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3f0e8-f6bd-49e0-9000-9f3dc122b6e6",
   "metadata": {},
   "source": [
    "#### 2. Use HoWDe in a self contained way (providing path to data and location to save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249eb6d-de2f-4453-86d2-285060f191cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Let HoWDe load data \n",
    "res2 = HoWDe_labelling(input_data=None, spark=None, HW_PATH=HW_PATH,\n",
    "                    SAVE_PATH=None, SAVE_NAME='', save_multiple=False,\n",
    "                    edit_config_default=None, \n",
    "                    range_window=42, bnd_none_day=6,\n",
    "                    bnd_none_home=[0.4,0.6], bnd_none_work=0.8,\n",
    "                    range_freq_home=0.2, range_freq_work_h=0.2,\n",
    "                    range_freq_work_d=0.2,\n",
    "                    driver_memory = 250\n",
    "                   )\n",
    "res2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e85c4-4bd9-4d72-8e94-51fa232624d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
